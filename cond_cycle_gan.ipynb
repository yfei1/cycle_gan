{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import (\n",
    "    Dense,\n",
    "    Activation,\n",
    "    BatchNormalization,\n",
    "    Conv2D,\n",
    "    Conv2DTranspose,\n",
    "    Input,\n",
    "    Add,\n",
    "    Reshape,\n",
    "    Concatenate,\n",
    "    MaxPool1D,\n",
    "    Dot\n",
    ")\n",
    "from keras.models import (\n",
    "    Sequential, Model\n",
    ")\n",
    "from keras.activations import (\n",
    "    softmax,\n",
    "    tanh,\n",
    "    sigmoid,\n",
    "    relu\n",
    ")\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (128, 128, 3)\n",
    "BATCH_SIZE = 1\n",
    "DIS_LR = 0.0002\n",
    "GEN_LR = 0.0002\n",
    "DECAY = .99\n",
    "X_PATH = './datasets/monet2photo/trainA'\n",
    "Y_PATH = './datasets/monet2photo/trainB'\n",
    "\n",
    "# Upsampling parameters\n",
    "NUM_CONV_LAYERS = 2\n",
    "INIT_FILTER = 16\n",
    "INIT_LENGTH = 64\n",
    "KERNEL_SIZE = (3, 3)\n",
    "CONV_STRIDES = (2, 2)\n",
    "\n",
    "# Residual Block parameters\n",
    "NUM_REPETITIONS = 2\n",
    "NUM_RES_BLOCKS = 2\n",
    "RES_STRIDES = (1, 1)\n",
    "\n",
    "# # WGAN parameters\n",
    "GRADIENT_PENALTY_WEIGHT = 10\n",
    "TRAINING_RATIO = 5  # the number of discriminator updates per generator update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leakyReLu(input_):\n",
    "    return relu(input_, alpha=.2)\n",
    "\n",
    "get_custom_objects().update({'leakyReLu': Activation(leakyReLu)})\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "Plot the images inline using matplotlib.\n",
    "\n",
    "This function takes in 8 pictures where \n",
    "\n",
    "X -> Original Picture X \n",
    "Y -> Original Picture Y\n",
    "Y' -> generator_xy(X)\n",
    "X' -> generator_yx(Y)\n",
    "Y'' -> generator_xy(X')\n",
    "X'' -> generator_yx(Y')\n",
    "X_identical -> generator_yx(X)\n",
    "Y_identical -> generator_xy(Y)\n",
    "\n",
    "\"\"\"\n",
    "def plot_images(*images):\n",
    "    assert(len(images) == 8)\n",
    "    image_names = ['X', 'Y', \"Y'\", \"X'\", \"X''\", \"Y''\", 'X_identical', 'Y_identical']\n",
    "    \n",
    "    # plt.rcParams['figure.figsize'] = [10, 10]\n",
    "    \n",
    "    for i, name in enumerate(image_names):\n",
    "        image = ((images[i] + 1) / 2 * 255.).astype(int)\n",
    "        plt.subplot(4, 2, i+1)\n",
    "        plt.imshow(image)\n",
    "        plt.title(name)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGAN:\n",
    "    def __init__(self):\n",
    "        config = tf.ConfigProto(allow_soft_placement=True)\n",
    "        config.gpu_options.allow_growth = True\n",
    "        self.session = tf.Session(config=config)\n",
    "        set_session(self.session)\n",
    "        \n",
    "        '''\n",
    "        with tf.device('/device:GPU:0'):\n",
    "            self.generator_xy = self.generator()\n",
    "            self.generator_yx = self.generator()\n",
    "        \n",
    "        with tf.device('/device:GPU:1'):\n",
    "            self.discriminator_x = self.discriminator()\n",
    "            self.discriminator_y = self.discriminator()\n",
    "        \n",
    "            self.xy_Dataset = self.buildDataset()\n",
    "        \n",
    "            X, Y     = Input(INPUT_SHAPE)   , Input(INPUT_SHAPE)\n",
    "            X_, Y_   = self.generator_yx(Y) , self.generator_xy(X)\n",
    "            X__, Y__ = self.generator_yx(Y_), self.generator_xy(X_)\n",
    "            X_identity, Y_identity = self.generator_yx(X), self.generator_xy(Y)\n",
    "\n",
    "            adam_dis = optimizers.Adam(lr=DIS_LR)\n",
    "            adam_gen = optimizers.Adam(lr=GEN_LR)\n",
    "        \n",
    "            self.discriminator_x.compile(loss='mse', optimizer=adam_dis, metrics=['accuracy'])\n",
    "            self.discriminator_y.compile(loss='mse', optimizer=adam_dis, metrics=['accuracy'])\n",
    "\n",
    "            self.discriminator_x.trainable = False\n",
    "            self.discriminator_y.trainable = False\n",
    "\n",
    "            X_valid, Y_valid = self.discriminator_x(X_), self.discriminator_y(Y_)\n",
    "        \n",
    "        with tf.device('/device:GPU:0'):\n",
    "            # TODO: Figure out the weights of the losses\n",
    "            self.generators = Model(\n",
    "                    inputs=[X, Y], \n",
    "                    outputs=[X_valid, Y_valid, X_, Y_, X__, Y__, X_identity, Y_identity]\n",
    "                )\n",
    "\n",
    "            # The paper suggests using L1 norm for the last four loss functions, try out different settings if it doesn't work\n",
    "            self.generators.compile(\n",
    "                loss=['mse']*8,\n",
    "                loss_weights=[1, 1, 0, 0, 10, 10, 1, 1],\n",
    "                optimizer=adam_gen\n",
    "            )\n",
    "        '''\n",
    "\n",
    "    def buildDataset(self, x_path = X_PATH, y_path = Y_PATH):        \n",
    "        x_Dataset = tf.data.Dataset.list_files( x_path + '/*.jpg')\n",
    "        y_Dataset = tf.data.Dataset.list_files( y_path + '/*.jpg')\n",
    "\n",
    "        x_images = x_Dataset.map(lambda x: tf.image.resize_images(tf.image.decode_jpeg(tf.read_file(x), channels = INPUT_SHAPE[2]), [INPUT_SHAPE[0], INPUT_SHAPE[1]]))\n",
    "        y_images = y_Dataset.map(lambda x: tf.image.resize_images(tf.image.decode_jpeg(tf.read_file(x), channels = INPUT_SHAPE[2]), [INPUT_SHAPE[0], INPUT_SHAPE[1]]))\n",
    "\n",
    "        xy_images = tf.data.Dataset.zip((x_images, y_images))\n",
    "        xy_Dataset = xy_images.batch(BATCH_SIZE)\n",
    "        return xy_Dataset\n",
    "\n",
    "    def discriminator(self):\n",
    "        pass\n",
    "\n",
    "    \n",
    "    # X is the output from last layer\n",
    "    # Y is the ground truth as a numpy array\n",
    "    def generator(self, x, y_dict):\n",
    "        _, init_len, _, _ = K.int_shape(x)\n",
    "        init_filters = INIT_FILTER\n",
    "        \n",
    "        curr = self.conv_res(x, y_dict, init_filters  , init_len)\n",
    "        curr = self.conv_res(curr, y_dict, init_filters*2, init_len//2)\n",
    "        curr = self.conv_res(curr, y_dict, init_filters*4, init_len//4)\n",
    "        # curr = self.conv_res(curr, y_dict, init_filters*8, init_len//8)\n",
    "        \n",
    "        # curr = self.deconv_res(curr, y_dict, init_filters*4  , init_len//8)\n",
    "        curr = self.deconv_res(curr, y_dict, init_filters*2, init_len//4)\n",
    "        curr = self.deconv_res(curr, y_dict, init_filters*1, init_len//2)\n",
    "        curr = self._addNonLocalBlock(curr)\n",
    "        curr = self.deconv_res(curr, y_dict, init_filters//2, init_len)\n",
    "        curr = self.deconv_res(curr, y_dict, init_filters//4, init_len*2)\n",
    "\n",
    "        return Model(inputs=[x] + list(y_dict.values()), outputs=[curr])\n",
    "    \n",
    "    \n",
    "    def conv_res(self, x, y_dict, filters, length):\n",
    "        curr = BatchNormalization(axis=3)(x)\n",
    "        curr = Activation('leakyReLu')(curr)\n",
    "        curr = Conv2D(filters, KERNEL_SIZE, strides=CONV_STRIDES, padding='same', kernel_initializer='truncated_normal')(curr)\n",
    "        curr = self._addResBlock(curr, y_dict, filters, length//2)\n",
    "        return curr\n",
    "    \n",
    "    def deconv_res(self, x, y_dict, filters, length):\n",
    "        curr = BatchNormalization(axis=3)(x)\n",
    "        curr = Activation('leakyReLu')(curr)\n",
    "        curr = Conv2DTranspose(filters, KERNEL_SIZE, strides=CONV_STRIDES, padding='same', kernel_initializer='truncated_normal')(curr)\n",
    "        curr = self._addResBlock(curr, y_dict, filters, length)\n",
    "        return curr\n",
    "\n",
    "    # ResBlock w repetition=2\n",
    "    def _addResBlock(self, x, y_dict, filters_in, x_len):\n",
    "        curr = x\n",
    "        \n",
    "        for _ in range(NUM_REPETITIONS):\n",
    "            curr = Concatenate(axis=3)([x, y_dict[x_len]])\n",
    "            curr = BatchNormalization(axis=3)(x)\n",
    "            curr = Activation('leakyReLu')(curr)\n",
    "            curr = Conv2D(filters_in, KERNEL_SIZE, strides=(1, 1), padding='same', kernel_initializer='truncated_normal')(curr)\n",
    "        \n",
    "        return Add()([curr, x])\n",
    "    \n",
    "    # Embedded Guassaian NonLocal Block\n",
    "    def _addNonLocalBlock(self, x, compression=2):\n",
    "        _, dim1, dim2, channels = K.int_shape(x)\n",
    "        intermediate_dim = channels // 2\n",
    "        \n",
    "        # theta \n",
    "        theta = Conv2D(intermediate_dim, KERNEL_SIZE, strides=(1, 1), padding='same', kernel_initializer='truncated_normal')(x)\n",
    "        theta = Reshape((-1, intermediate_dim))(theta)\n",
    "        # phi \n",
    "        phi = Conv2D(intermediate_dim, KERNEL_SIZE, strides=(1, 1), padding='same', kernel_initializer='truncated_normal')(x)\n",
    "        phi = Reshape((-1, intermediate_dim))(phi)\n",
    "        phi = MaxPool1D(compression)(phi)\n",
    "        \n",
    "        # f\n",
    "        f = Dot(axes=2)([theta, phi])\n",
    "        f = Activation('softmax')(f)\n",
    "\n",
    "        # g\n",
    "        g = Conv2D(intermediate_dim, KERNEL_SIZE, strides=(1, 1), padding='same', kernel_initializer='truncated_normal')(x)\n",
    "        g = Reshape((-1, intermediate_dim))(g)\n",
    "        g = MaxPool1D(compression)(g)\n",
    "\n",
    "        out = Dot(axes=(2, 1))([f, g])\n",
    "        out = Reshape((dim1, dim2, intermediate_dim))(out)\n",
    "        out = Conv2D(channels, KERNEL_SIZE, strides=(1, 1), padding='same', kernel_initializer='truncated_normal')(out)\n",
    "\n",
    "        # residual connection\n",
    "        return Add()([x, out])\n",
    "\n",
    "    \n",
    "    # should label generated samples -1 and real samples 1\n",
    "    def wasserstein_loss(y_true, y_pred):\n",
    "        return K.mean(y_true * y_pred)\n",
    "\n",
    "    # need to generate random weighted-averages of real and generated samples, to feed the discriminator\n",
    "    # and use for the gradient norm penalty.\n",
    "    def gradient_penalty_loss(y_true, y_pred, averaged_samples, gradient_penalty_weight):\n",
    "        gradients = K.gradients(y_pred, averaged_samples)[0]\n",
    "        gradients_sqr = K.square(gradients)\n",
    "        gradients_sqr_sum = K.sum(gradients_sqr, axis=np.arange(1, len(gradients_sqr.shape)))\n",
    "        gradient_l2_norm = K.sqrt(gradients_sqr_sum)\n",
    "        gradient_penalty = gradient_penalty_weight * K.square(1 - gradient_l2_norm)\n",
    "        return K.mean(gradient_penalty)\n",
    "        \n",
    "    '''\n",
    "    def _addDeconvBlock(self, model, activations, filters, kernel_size=KERNEL_SIZE, strides=CONV_STRIDES):\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "        model.add(Activation(activation_func(activations)))\n",
    "        \n",
    "        model.add(UpSampling2D(size=2))\n",
    "        model.add(Conv2D(filters=filters, kernel_size=kernel_size, strides=(1,1), padding='same', kernel_initializer='truncated_normal'))\n",
    "        #model.add(Conv2DTranspose(filters=filters, kernel_size=kernel_size, strides=strides, padding='same'))\n",
    "\n",
    "    def _addConvBlock(self, model, activations, filters, kernel_size, strides, input_layer=False):\n",
    "        if not input_layer:\n",
    "            model.add(BatchNormalization(axis=3))\n",
    "            model.add(Activation(activation_func(activations)))\n",
    "            model.add(Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding='same', kernel_initializer='truncated_normal'))\n",
    "        else:\n",
    "            model.add(Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding='same', input_shape=INPUT_SHAPE, kernel_initializer='truncated_normal'))\n",
    "    \n",
    "    \n",
    "    def train(self):\n",
    "        # TODO: implements training process\n",
    "        valid = np.ones((BATCH_SIZE, 1)) * .9\n",
    "        fake  = np.zeros((BATCH_SIZE, 1))\n",
    "        \n",
    "        # self.discriminator_x.summary()\n",
    "        # self.discriminator_y.summary()\n",
    "        # self.generators.summary()\n",
    "        \n",
    "        for epoch in range(0,10):\n",
    "            iterator = self.xy_Dataset.make_initializable_iterator()\n",
    "            (x_next, y_next) = iterator.get_next()\n",
    "            self.session.run(iterator.initializer)\n",
    "            batch_i = 0\n",
    "            \n",
    "            while True:\n",
    "                try:\n",
    "                    # x_train, y_train = np.random.normal(size=[BATCH_SIZE, 256, 256, 3]), np.random.normal(size=[BATCH_SIZE, 256, 256, 3])\n",
    "                    x_train, y_train = self.session.run([x_next, y_next])\n",
    "                    \n",
    "                    if x_train.shape[0] != BATCH_SIZE:\n",
    "                        break\n",
    "                    \n",
    "                    x_train = (x_train / 255.0 - .5) * 2\n",
    "                    y_train = (y_train / 255.0 - .5) * 2\n",
    "                    \n",
    "                    with tf.device('/device:GPU:1'):\n",
    "                        x_valid, y_valid, x_, y_, x__, y__, x_identity, y_identity = self.generators.predict([x_train, y_train])\n",
    "                        \n",
    "                        d_x_real_loss = self.discriminator_x.train_on_batch(x_train, valid)\n",
    "                        d_x_fake_loss = self.discriminator_x.train_on_batch(x_, fake)\n",
    "                        d_x_loss = 0.5 * np.add(d_x_real_loss, d_x_fake_loss)\n",
    "\n",
    "                        d_y_real_loss = self.discriminator_y.train_on_batch(y_train, valid)\n",
    "                        d_y_fake_loss = self.discriminator_y.train_on_batch(y_, fake)\n",
    "                        d_y_loss = 0.5 * np.add(d_y_real_loss, d_y_fake_loss)\n",
    "\n",
    "                        # Total disciminator loss\n",
    "                        d_loss = 0.5 * np.add(d_x_loss, d_y_loss)\n",
    "                        \n",
    "                    \n",
    "                        # Total generator loss\n",
    "                        g_loss = self.generators.train_on_batch([x_train, y_train],\n",
    "                                                                [valid, valid,\n",
    "                                                                 x_train, y_train,\n",
    "                                                                 x_train, y_train,\n",
    "                                                                 x_train, y_train])\n",
    "\n",
    "                        if batch_i % 10 == 0:\n",
    "                            plot_images(\n",
    "                                x_train[0], y_train[0],\n",
    "                                y_[0], x_[0],\n",
    "                                x__[0], y__[0],\n",
    "                                x_identity[0], y_identity[0]\n",
    "                            )\n",
    "\n",
    "                            print(\n",
    "                                'Epoch: ', epoch,\n",
    "                                'Batch: ', batch_i,\n",
    "                                'Loss of Discriminator: ', d_loss, \n",
    "                                'Loss of Generator G: ', g_loss\n",
    "                            )\n",
    "\n",
    "                        batch_i += 1\n",
    "                    \n",
    "                \n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    print('epoch ' + str( epoch) + ' end.')\n",
    "                    break\n",
    "    '''\n",
    "\n",
    "    def test(self, x_test, y_test):\n",
    "        # TODO: implements evaluation \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_109 (InputLayer)          (None, 128, 128, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_266 (BatchN (None, 128, 128, 3)  12          input_109[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_275 (Activation)     (None, 128, 128, 3)  0           batch_normalization_266[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_253 (Conv2D)             (None, 64, 64, 16)   448         activation_275[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_268 (BatchN (None, 64, 64, 16)   64          conv2d_253[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_277 (Activation)     (None, 64, 64, 16)   0           batch_normalization_268[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_255 (Conv2D)             (None, 64, 64, 16)   2320        activation_277[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_91 (Add)                    (None, 64, 64, 16)   0           conv2d_255[0][0]                 \n",
      "                                                                 conv2d_253[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_269 (BatchN (None, 64, 64, 16)   64          add_91[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_278 (Activation)     (None, 64, 64, 16)   0           batch_normalization_269[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_256 (Conv2D)             (None, 32, 32, 32)   4640        activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_271 (BatchN (None, 32, 32, 32)   128         conv2d_256[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_280 (Activation)     (None, 32, 32, 32)   0           batch_normalization_271[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_258 (Conv2D)             (None, 32, 32, 32)   9248        activation_280[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_92 (Add)                    (None, 32, 32, 32)   0           conv2d_258[0][0]                 \n",
      "                                                                 conv2d_256[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_272 (BatchN (None, 32, 32, 32)   128         add_92[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_281 (Activation)     (None, 32, 32, 32)   0           batch_normalization_272[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_259 (Conv2D)             (None, 16, 16, 64)   18496       activation_281[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_274 (BatchN (None, 16, 16, 64)   256         conv2d_259[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_283 (Activation)     (None, 16, 16, 64)   0           batch_normalization_274[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_261 (Conv2D)             (None, 16, 16, 64)   36928       activation_283[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_93 (Add)                    (None, 16, 16, 64)   0           conv2d_261[0][0]                 \n",
      "                                                                 conv2d_259[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_275 (BatchN (None, 16, 16, 64)   256         add_93[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_284 (Activation)     (None, 16, 16, 64)   0           batch_normalization_275[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_42 (Conv2DTran (None, 32, 32, 32)   18464       activation_284[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_277 (BatchN (None, 32, 32, 32)   128         conv2d_transpose_42[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_286 (Activation)     (None, 32, 32, 32)   0           batch_normalization_277[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_263 (Conv2D)             (None, 32, 32, 32)   9248        activation_286[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_94 (Add)                    (None, 32, 32, 32)   0           conv2d_263[0][0]                 \n",
      "                                                                 conv2d_transpose_42[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_278 (BatchN (None, 32, 32, 32)   128         add_94[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_287 (Activation)     (None, 32, 32, 32)   0           batch_normalization_278[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_43 (Conv2DTran (None, 64, 64, 16)   4624        activation_287[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_280 (BatchN (None, 64, 64, 16)   64          conv2d_transpose_43[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_289 (Activation)     (None, 64, 64, 16)   0           batch_normalization_280[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_265 (Conv2D)             (None, 64, 64, 16)   2320        activation_289[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_95 (Add)                    (None, 64, 64, 16)   0           conv2d_265[0][0]                 \n",
      "                                                                 conv2d_transpose_43[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_267 (Conv2D)             (None, 64, 64, 8)    1160        add_95[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_266 (Conv2D)             (None, 64, 64, 8)    1160        add_95[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_32 (Reshape)            (None, 4096, 8)      0           conv2d_267[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_31 (Reshape)            (None, 4096, 8)      0           conv2d_266[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling1D) (None, 2048, 8)      0           reshape_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_268 (Conv2D)             (None, 64, 64, 8)    1160        add_95[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_13 (Dot)                    (None, 4096, 2048)   0           reshape_31[0][0]                 \n",
      "                                                                 max_pooling1d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "reshape_33 (Reshape)            (None, 4096, 8)      0           conv2d_268[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_290 (Activation)     (None, 4096, 2048)   0           dot_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling1D) (None, 2048, 8)      0           reshape_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_14 (Dot)                    (None, 4096, 8)      0           activation_290[0][0]             \n",
      "                                                                 max_pooling1d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "reshape_34 (Reshape)            (None, 64, 64, 8)    0           dot_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_269 (Conv2D)             (None, 64, 64, 16)   1168        reshape_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_96 (Add)                    (None, 64, 64, 16)   0           add_95[0][0]                     \n",
      "                                                                 conv2d_269[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_281 (BatchN (None, 64, 64, 16)   64          add_96[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_291 (Activation)     (None, 64, 64, 16)   0           batch_normalization_281[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_44 (Conv2DTran (None, 128, 128, 8)  1160        activation_291[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_283 (BatchN (None, 128, 128, 8)  32          conv2d_transpose_44[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_293 (Activation)     (None, 128, 128, 8)  0           batch_normalization_283[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_271 (Conv2D)             (None, 128, 128, 8)  584         activation_293[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_97 (Add)                    (None, 128, 128, 8)  0           conv2d_271[0][0]                 \n",
      "                                                                 conv2d_transpose_44[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_284 (BatchN (None, 128, 128, 8)  32          add_97[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_294 (Activation)     (None, 128, 128, 8)  0           batch_normalization_284[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_45 (Conv2DTran (None, 256, 256, 4)  292         activation_294[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_286 (BatchN (None, 256, 256, 4)  16          conv2d_transpose_45[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_296 (Activation)     (None, 256, 256, 4)  0           batch_normalization_286[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_273 (Conv2D)             (None, 256, 256, 4)  148         activation_296[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_98 (Add)                    (None, 256, 256, 4)  0           conv2d_273[0][0]                 \n",
      "                                                                 conv2d_transpose_45[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 114,940\n",
      "Trainable params: 114,254\n",
      "Non-trainable params: 686\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = Input(shape=INPUT_SHAPE)\n",
    "y = Input(shape=INPUT_SHAPE)\n",
    "lens = [int(K.int_shape(y)[1] // 2**i) for i in [-2, -1, 0, 1, 2, 3, 4]]\n",
    "y_dict = {i : Input(shape=(i, i, 3)) for i in lens}\n",
    "y_dict = OrderedDict(sorted(y_dict.items(), key=lambda t: t[0]))\n",
    "cycleGAN = CycleGAN()\n",
    "generator = cycleGAN.generator(x, y_dict)\n",
    "\n",
    "Xs = np.random.normal(size=(10, 128, 128, 3))\n",
    "Ys = np.random.normal(size=(10, 128, 128, 3))\n",
    "y_keys = list(y_dict.keys())\n",
    "\n",
    "y_in = [np.array([cv2.resize(Y, (i, i)) for Y in Ys]) for i in y_keys]\n",
    "\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 256, 256, 4)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.predict([Xs]+y_in).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.compile('adam', 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "10/10 [==============================] - 4s 425ms/step - loss: 1.0410\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f556b53a978>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.fit([Xs]+y_in, np.random.normal(size=(10, 256, 256, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
