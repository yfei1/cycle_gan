{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import (\n",
    "    Dense,\n",
    "    Activation,\n",
    "    BatchNormalization,\n",
    "    Conv2D,\n",
    "    Conv2DTranspose,\n",
    "    Input,\n",
    "    Add,\n",
    "    Reshape,\n",
    "    Concatenate,\n",
    "    MaxPool1D,\n",
    "    Dot,\n",
    "    GlobalAveragePooling2D,\n",
    "    Embedding\n",
    ")\n",
    "from keras.models import (\n",
    "    Sequential, Model\n",
    ")\n",
    "from keras.activations import (\n",
    "    softmax,\n",
    "    tanh,\n",
    "    sigmoid,\n",
    "    relu\n",
    ")\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "from utils.utils import GroupNormalization\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (128, 128, 3)\n",
    "BATCH_SIZE = 1\n",
    "DIS_LR = 0.0002\n",
    "GEN_LR = 0.0002\n",
    "DECAY = .99\n",
    "X_PATH = './datasets/monet2photo/trainA'\n",
    "Y_PATH = './datasets/monet2photo/trainB'\n",
    "\n",
    "# Upsampling parameters\n",
    "NUM_CONV_LAYERS = 2\n",
    "INIT_FILTER = 16\n",
    "INIT_LENGTH = 64\n",
    "KERNEL_SIZE = (3, 3)\n",
    "CONV_STRIDES = (2, 2)\n",
    "\n",
    "# Residual Block parameters\n",
    "NUM_REPETITIONS = 2\n",
    "NUM_RES_BLOCKS = 2\n",
    "RES_STRIDES = (1, 1)\n",
    "\n",
    "# # WGAN parameters\n",
    "GRADIENT_PENALTY_WEIGHT = 10\n",
    "TRAINING_RATIO = 5  # the number of discriminator updates per generator update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leakyReLu(input_):\n",
    "    return relu(input_, alpha=.2)\n",
    "\n",
    "get_custom_objects().update({'leakyReLu': Activation(leakyReLu)})\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "Plot the images inline using matplotlib.\n",
    "\n",
    "This function takes in 8 pictures where \n",
    "\n",
    "X -> Original Picture X \n",
    "Y -> Original Picture Y\n",
    "Y' -> generator_xy(X)\n",
    "X' -> generator_yx(Y)\n",
    "Y'' -> generator_xy(X')\n",
    "X'' -> generator_yx(Y')\n",
    "X_identical -> generator_yx(X)\n",
    "Y_identical -> generator_xy(Y)\n",
    "\n",
    "\"\"\"\n",
    "def plot_images(*images):\n",
    "    assert(len(images) == 8)\n",
    "    image_names = ['X', 'Y', \"Y'\", \"X'\", \"X''\", \"Y''\", 'X_identical', 'Y_identical']\n",
    "    \n",
    "    # plt.rcParams['figure.figsize'] = [10, 10]\n",
    "    \n",
    "    for i, name in enumerate(image_names):\n",
    "        image = ((images[i] + 1) / 2 * 255.).astype(int)\n",
    "        plt.subplot(4, 2, i+1)\n",
    "        plt.imshow(image)\n",
    "        plt.title(name)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGAN:\n",
    "    def __init__(self):\n",
    "        config = tf.ConfigProto(allow_soft_placement=True)\n",
    "        config.gpu_options.allow_growth = True\n",
    "        self.session = tf.Session(config=config)\n",
    "        set_session(self.session)\n",
    "        \n",
    "        '''\n",
    "        with tf.device('/device:GPU:0'):\n",
    "            self.generator_xy = self.generator()\n",
    "            self.generator_yx = self.generator()\n",
    "        \n",
    "        with tf.device('/device:GPU:1'):\n",
    "            self.discriminator_x = self.discriminator()\n",
    "            self.discriminator_y = self.discriminator()\n",
    "        \n",
    "            self.xy_Dataset = self.buildDataset()\n",
    "        \n",
    "            X, Y     = Input(INPUT_SHAPE)   , Input(INPUT_SHAPE)\n",
    "            X_, Y_   = self.generator_yx(Y) , self.generator_xy(X)\n",
    "            X__, Y__ = self.generator_yx(Y_), self.generator_xy(X_)\n",
    "            X_identity, Y_identity = self.generator_yx(X), self.generator_xy(Y)\n",
    "\n",
    "            adam_dis = optimizers.Adam(lr=DIS_LR)\n",
    "            adam_gen = optimizers.Adam(lr=GEN_LR)\n",
    "        \n",
    "            self.discriminator_x.compile(loss='mse', optimizer=adam_dis, metrics=['accuracy'])\n",
    "            self.discriminator_y.compile(loss='mse', optimizer=adam_dis, metrics=['accuracy'])\n",
    "\n",
    "            self.discriminator_x.trainable = False\n",
    "            self.discriminator_y.trainable = False\n",
    "\n",
    "            X_valid, Y_valid = self.discriminator_x(X_), self.discriminator_y(Y_)\n",
    "        \n",
    "        with tf.device('/device:GPU:0'):\n",
    "            # TODO: Figure out the weights of the losses\n",
    "            self.generators = Model(\n",
    "                    inputs=[X, Y], \n",
    "                    outputs=[X_valid, Y_valid, X_, Y_, X__, Y__, X_identity, Y_identity]\n",
    "                )\n",
    "\n",
    "            # The paper suggests using L1 norm for the last four loss functions, try out different settings if it doesn't work\n",
    "            self.generators.compile(\n",
    "                loss=['mse']*8,\n",
    "                loss_weights=[1, 1, 0, 0, 10, 10, 1, 1],\n",
    "                optimizer=adam_gen\n",
    "            )\n",
    "        '''\n",
    "\n",
    "    def buildDataset(self, x_path = X_PATH, y_path = Y_PATH):        \n",
    "        x_Dataset = tf.data.Dataset.list_files( x_path + '/*.jpg')\n",
    "        y_Dataset = tf.data.Dataset.list_files( y_path + '/*.jpg')\n",
    "\n",
    "        x_images = x_Dataset.map(lambda x: tf.image.resize_images(tf.image.decode_jpeg(tf.read_file(x), channels = INPUT_SHAPE[2]), [INPUT_SHAPE[0], INPUT_SHAPE[1]]))\n",
    "        y_images = y_Dataset.map(lambda x: tf.image.resize_images(tf.image.decode_jpeg(tf.read_file(x), channels = INPUT_SHAPE[2]), [INPUT_SHAPE[0], INPUT_SHAPE[1]]))\n",
    "\n",
    "        xy_images = tf.data.Dataset.zip((x_images, y_images))\n",
    "        xy_Dataset = xy_images.batch(BATCH_SIZE)\n",
    "        return xy_Dataset\n",
    "\n",
    "    def discriminator(self, x, y):\n",
    "        # X is the image waiting to be judged\n",
    "        # Y is the ground truth as a numpy array\n",
    "        # Batch Size = None, Height, Width, Channels\n",
    "        _, init_len, _, _ = K.int_shape(x)\n",
    "        init_filters = INIT_FILTER\n",
    "        x_feature = self.conv2d_layer(x)\n",
    "        y_feature = self.conv2d_layer(y)\n",
    "\n",
    "        # linear product of curr and y\n",
    "        linearProductOutput = Dot(axes = 1)([x_feature, y_feature])\n",
    "        linearOutput = Dense(init_filters*8)(x_feature)\n",
    "        \n",
    "        curr = Add()([linearOutput, linearProductOutput])\n",
    "        return Model(inputs=[x, y], outputs=[curr])\n",
    "    \n",
    "    def conv2d_layer(self, x):\n",
    "        init_filters = INIT_FILTER\n",
    "        # 6 layers of resblock\n",
    "        curr = self.d_resblock(x, init_filters)\n",
    "        curr = self.d_resblock(curr, init_filters*2)\n",
    "        curr = self.d_resblock(curr, init_filters*4)\n",
    "        curr = self.d_resblock(curr, init_filters*8)\n",
    "        curr = self.d_resblock(curr, init_filters*8, False)\n",
    "        curr = Activation('relu')(curr)\n",
    "        \n",
    "        # apply global sum pooling\n",
    "#         _, height, _, _ = K.int_shape(curr)\n",
    "#         curr = GlobalAveragePooling2D(curr) # 2D tensor with shape: (batch_size, channels)\n",
    "        curr = K.sum(curr, axis=(1,2))\n",
    "        return curr\n",
    "        \n",
    "        \n",
    "    \n",
    "    def d_resblock(self, x, filters, size_change = True):\n",
    "        # resblock for the descriminator\n",
    "        # if the input and output shape are different, set size_change to true\n",
    "        curr = GroupNormalization()(x) # ? axis=?\n",
    "        curr = Activation('relu')(curr)\n",
    "        \n",
    "        if size_change:\n",
    "            temp_x = Conv2D(filters, KERNEL_SIZE, strides=CONV_STRIDES, padding='same', kernel_initializer='truncated_normal')(curr)\n",
    "        else:\n",
    "            temp_x = curr\n",
    "        \n",
    "        curr = GroupNormalization()(temp_x)\n",
    "        curr = Activation('relu')(curr)\n",
    "        curr = Conv2D(filters, KERNEL_SIZE, strides=(1,1), padding='same', kernel_initializer='truncated_normal')(curr)\n",
    "        curr = GroupNormalization()(curr)\n",
    "        curr = Activation('relu')(curr)\n",
    "        curr = Conv2D(filters, KERNEL_SIZE, strides=(1,1), padding='same', kernel_initializer='truncated_normal')(curr)\n",
    "        return  Add()([temp_x, curr])\n",
    "    \n",
    "    # X is the output from last layer\n",
    "    # Y is the ground truth as a numpy array\n",
    "    def generator(self, x, y_dict):\n",
    "        _, init_len, _, _ = K.int_shape(x)\n",
    "        init_filters = INIT_FILTER\n",
    "        \n",
    "        curr = self.conv_res(x, y_dict, init_filters  , init_len)\n",
    "        curr = self.conv_res(curr, y_dict, init_filters*2, init_len//2)\n",
    "        curr = self.conv_res(curr, y_dict, init_filters*4, init_len//4)\n",
    "        # curr = self.conv_res(curr, y_dict, init_filters*8, init_len//8)\n",
    "        \n",
    "        # curr = self.deconv_res(curr, y_dict, init_filters*4  , init_len//8)\n",
    "        curr = self.deconv_res(curr, y_dict, init_filters*2, init_len//4)\n",
    "        curr = self.deconv_res(curr, y_dict, init_filters*1, init_len//2)\n",
    "        curr = self._addNonLocalBlock(curr)\n",
    "        curr = self.deconv_res(curr, y_dict, init_filters//2, init_len)\n",
    "        curr = self.deconv_res(curr, y_dict, init_filters//4, init_len*2)\n",
    "\n",
    "        return Model(inputs=[x] + list(y_dict.values()), outputs=[curr])\n",
    "    \n",
    "    \n",
    "    def conv_res(self, x, y_dict, filters, length):\n",
    "        curr = BatchNormalization(axis=3)(x)\n",
    "        curr = Activation('leakyReLu')(curr)\n",
    "        curr = Conv2D(filters, KERNEL_SIZE, strides=CONV_STRIDES, padding='same', kernel_initializer='truncated_normal')(curr)\n",
    "        curr = self._addResBlock(curr, y_dict, filters, length//2)\n",
    "        return curr\n",
    "    \n",
    "    def deconv_res(self, x, y_dict, filters, length):\n",
    "        curr = BatchNormalization(axis=3)(x)\n",
    "        curr = Activation('leakyReLu')(curr)\n",
    "        curr = Conv2DTranspose(filters, KERNEL_SIZE, strides=CONV_STRIDES, padding='same', kernel_initializer='truncated_normal')(curr)\n",
    "        curr = self._addResBlock(curr, y_dict, filters, length)\n",
    "        return curr\n",
    "\n",
    "    # ResBlock w repetition=2\n",
    "    def _addResBlock(self, x, y_dict, filters_in, x_len):\n",
    "        curr = x\n",
    "        \n",
    "        for _ in range(NUM_REPETITIONS):\n",
    "            curr = Concatenate(axis=3)([x, y_dict[x_len]])\n",
    "            curr = BatchNormalization(axis=3)(x)\n",
    "            curr = Activation('leakyReLu')(curr)\n",
    "            curr = Conv2D(filters_in, KERNEL_SIZE, strides=(1, 1), padding='same', kernel_initializer='truncated_normal')(curr)\n",
    "        \n",
    "        return Add()([curr, x])\n",
    "    \n",
    "    # Embedded Guassaian NonLocal Block\n",
    "    def _addNonLocalBlock(self, x, compression=2):\n",
    "        _, dim1, dim2, channels = K.int_shape(x)\n",
    "        intermediate_dim = channels // 2\n",
    "        \n",
    "        # theta \n",
    "        theta = Conv2D(intermediate_dim, KERNEL_SIZE, strides=(1, 1), padding='same', kernel_initializer='truncated_normal')(x)\n",
    "        theta = Reshape((-1, intermediate_dim))(theta)\n",
    "        # phi \n",
    "        phi = Conv2D(intermediate_dim, KERNEL_SIZE, strides=(1, 1), padding='same', kernel_initializer='truncated_normal')(x)\n",
    "        phi = Reshape((-1, intermediate_dim))(phi)\n",
    "        phi = MaxPool1D(compression)(phi)\n",
    "        \n",
    "        # f\n",
    "        f = Dot(axes=2)([theta, phi])\n",
    "        f = Activation('softmax')(f)\n",
    "\n",
    "        # g\n",
    "        g = Conv2D(intermediate_dim, KERNEL_SIZE, strides=(1, 1), padding='same', kernel_initializer='truncated_normal')(x)\n",
    "        g = Reshape((-1, intermediate_dim))(g)\n",
    "        g = MaxPool1D(compression)(g)\n",
    "\n",
    "        out = Dot(axes=(2, 1))([f, g])\n",
    "        out = Reshape((dim1, dim2, intermediate_dim))(out)\n",
    "        out = Conv2D(channels, KERNEL_SIZE, strides=(1, 1), padding='same', kernel_initializer='truncated_normal')(out)\n",
    "\n",
    "        # residual connection\n",
    "        return Add()([x, out])\n",
    "\n",
    "    \n",
    "    # should label generated samples -1 and real samples 1\n",
    "    def wasserstein_loss(y_true, y_pred):\n",
    "        return K.mean(y_true * y_pred)\n",
    "\n",
    "    # need to generate random weighted-averages of real and generated samples, to feed the discriminator\n",
    "    # and use for the gradient norm penalty.\n",
    "    def gradient_penalty_loss(y_true, y_pred, averaged_samples, gradient_penalty_weight):\n",
    "        gradients = K.gradients(y_pred, averaged_samples)[0]\n",
    "        gradients_sqr = K.square(gradients)\n",
    "        gradients_sqr_sum = K.sum(gradients_sqr, axis=np.arange(1, len(gradients_sqr.shape)))\n",
    "        gradient_l2_norm = K.sqrt(gradients_sqr_sum)\n",
    "        gradient_penalty = gradient_penalty_weight * K.square(1 - gradient_l2_norm)\n",
    "        return K.mean(gradient_penalty)\n",
    "        \n",
    "    '''\n",
    "    def _addDeconvBlock(self, model, activations, filters, kernel_size=KERNEL_SIZE, strides=CONV_STRIDES):\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "        model.add(Activation(activation_func(activations)))\n",
    "        \n",
    "        model.add(UpSampling2D(size=2))\n",
    "        model.add(Conv2D(filters=filters, kernel_size=kernel_size, strides=(1,1), padding='same', kernel_initializer='truncated_normal'))\n",
    "        #model.add(Conv2DTranspose(filters=filters, kernel_size=kernel_size, strides=strides, padding='same'))\n",
    "\n",
    "    def _addConvBlock(self, model, activations, filters, kernel_size, strides, input_layer=False):\n",
    "        if not input_layer:\n",
    "            model.add(BatchNormalization(axis=3))\n",
    "            model.add(Activation(activation_func(activations)))\n",
    "            model.add(Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding='same', kernel_initializer='truncated_normal'))\n",
    "        else:\n",
    "            model.add(Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding='same', input_shape=INPUT_SHAPE, kernel_initializer='truncated_normal'))\n",
    "    \n",
    "    \n",
    "    def train(self):\n",
    "        # TODO: implements training process\n",
    "        valid = np.ones((BATCH_SIZE, 1)) * .9\n",
    "        fake  = np.zeros((BATCH_SIZE, 1))\n",
    "        \n",
    "        # self.discriminator_x.summary()\n",
    "        # self.discriminator_y.summary()\n",
    "        # self.generators.summary()\n",
    "        \n",
    "        for epoch in range(0,10):\n",
    "            iterator = self.xy_Dataset.make_initializable_iterator()\n",
    "            (x_next, y_next) = iterator.get_next()\n",
    "            self.session.run(iterator.initializer)\n",
    "            batch_i = 0\n",
    "            \n",
    "            while True:\n",
    "                try:\n",
    "                    # x_train, y_train = np.random.normal(size=[BATCH_SIZE, 256, 256, 3]), np.random.normal(size=[BATCH_SIZE, 256, 256, 3])\n",
    "                    x_train, y_train = self.session.run([x_next, y_next])\n",
    "                    \n",
    "                    if x_train.shape[0] != BATCH_SIZE:\n",
    "                        break\n",
    "                    \n",
    "                    x_train = (x_train / 255.0 - .5) * 2\n",
    "                    y_train = (y_train / 255.0 - .5) * 2\n",
    "                    \n",
    "                    with tf.device('/device:GPU:1'):\n",
    "                        x_valid, y_valid, x_, y_, x__, y__, x_identity, y_identity = self.generators.predict([x_train, y_train])\n",
    "                        \n",
    "                        d_x_real_loss = self.discriminator_x.train_on_batch(x_train, valid)\n",
    "                        d_x_fake_loss = self.discriminator_x.train_on_batch(x_, fake)\n",
    "                        d_x_loss = 0.5 * np.add(d_x_real_loss, d_x_fake_loss)\n",
    "\n",
    "                        d_y_real_loss = self.discriminator_y.train_on_batch(y_train, valid)\n",
    "                        d_y_fake_loss = self.discriminator_y.train_on_batch(y_, fake)\n",
    "                        d_y_loss = 0.5 * np.add(d_y_real_loss, d_y_fake_loss)\n",
    "\n",
    "                        # Total disciminator loss\n",
    "                        d_loss = 0.5 * np.add(d_x_loss, d_y_loss)\n",
    "                        \n",
    "                    \n",
    "                        # Total generator loss\n",
    "                        g_loss = self.generators.train_on_batch([x_train, y_train],\n",
    "                                                                [valid, valid,\n",
    "                                                                 x_train, y_train,\n",
    "                                                                 x_train, y_train,\n",
    "                                                                 x_train, y_train])\n",
    "\n",
    "                        if batch_i % 10 == 0:\n",
    "                            plot_images(\n",
    "                                x_train[0], y_train[0],\n",
    "                                y_[0], x_[0],\n",
    "                                x__[0], y__[0],\n",
    "                                x_identity[0], y_identity[0]\n",
    "                            )\n",
    "\n",
    "                            print(\n",
    "                                'Epoch: ', epoch,\n",
    "                                'Batch: ', batch_i,\n",
    "                                'Loss of Discriminator: ', d_loss, \n",
    "                                'Loss of Generator G: ', g_loss\n",
    "                            )\n",
    "\n",
    "                        batch_i += 1\n",
    "                    \n",
    "                \n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    print('epoch ' + str( epoch) + ' end.')\n",
    "                    break\n",
    "    '''\n",
    "\n",
    "    def test(self, x_test, y_test):\n",
    "        # TODO: implements evaluation \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute '_inbound_nodes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-918d2f287ab9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcycleGAN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCycleGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#generator = cycleGAN.generator(x, y_dict)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcycleGAN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#Xs = np.random.normal(size=(10, 128, 128, 3))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-f9637e3cc185>\u001b[0m in \u001b[0;36mdiscriminator\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mcurr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlinearOutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinearProductOutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconv2d_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 'inputs' in kwargs and 'outputs' in kwargs):\n\u001b[1;32m     92\u001b[0m             \u001b[0;31m# Graph network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;31m# Subclassed network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;31m# Keep track of the network's nodes and layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         nodes, nodes_by_depth, layers, layers_by_depth = _map_graph_network(\n\u001b[0;32m--> 231\u001b[0;31m             self.inputs, self.outputs)\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_network_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes_by_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes_by_depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m_map_graph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m   1364\u001b[0m                   \u001b[0mlayer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m                   \u001b[0mnode_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1366\u001b[0;31m                   tensor_index=tensor_index)\n\u001b[0m\u001b[1;32m   1367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes_in_decreasing_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mbuild_map\u001b[0;34m(tensor, finished_nodes, nodes_in_progress, layer, node_index, tensor_index)\u001b[0m\n\u001b[1;32m   1351\u001b[0m             \u001b[0mtensor_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m             build_map(x, finished_nodes, nodes_in_progress, layer,\n\u001b[0;32m-> 1353\u001b[0;31m                       node_index, tensor_index)\n\u001b[0m\u001b[1;32m   1354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m         \u001b[0mfinished_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mbuild_map\u001b[0;34m(tensor, finished_nodes, nodes_in_progress, layer, node_index, tensor_index)\u001b[0m\n\u001b[1;32m   1351\u001b[0m             \u001b[0mtensor_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m             build_map(x, finished_nodes, nodes_in_progress, layer,\n\u001b[0;32m-> 1353\u001b[0;31m                       node_index, tensor_index)\n\u001b[0m\u001b[1;32m   1354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m         \u001b[0mfinished_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mbuild_map\u001b[0;34m(tensor, finished_nodes, nodes_in_progress, layer, node_index, tensor_index)\u001b[0m\n\u001b[1;32m   1323\u001b[0m             \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcycle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mdetected\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \"\"\"\n\u001b[0;32m-> 1325\u001b[0;31m         \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m         \u001b[0;31m# Prevent cycles.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute '_inbound_nodes'"
     ]
    }
   ],
   "source": [
    "x = Input(shape=INPUT_SHAPE)\n",
    "y = Input(shape=INPUT_SHAPE)\n",
    "lens = [int(K.int_shape(y)[1] // 2**i) for i in [-2, -1, 0, 1, 2, 3, 4]]\n",
    "y_dict = {i : Input(shape=(i, i, 3)) for i in lens}\n",
    "y_dict = OrderedDict(sorted(y_dict.items(), key=lambda t: t[0]))\n",
    "cycleGAN = CycleGAN()\n",
    "#generator = cycleGAN.generator(x, y_dict)\n",
    "d = cycleGAN.discriminator(x, y)\n",
    "\n",
    "#Xs = np.random.normal(size=(10, 128, 128, 3))\n",
    "#Ys = np.random.normal(size=(10, 128, 128, 3))\n",
    "#y_keys = list(y_dict.keys())\n",
    "\n",
    "#y_in = [np.array([cv2.resize(Y, (i, i)) for Y in Ys]) for i in y_keys]\n",
    "\n",
    "#generator.summary()\n",
    "d.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.predict([Xs]+y_in).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.compile('adam', 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.fit([Xs]+y_in, np.random.normal(size=(10, 256, 256, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
